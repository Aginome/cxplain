{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explaining Natural Language Processing (NLP) Models with CXPlain\n",
    "\n",
    "First, we load a number of reviews from the Internet Movie Database (IMDB) dataset which we will use as a training dataset to attempt to recognise the sentiment \n",
    "expressed in a given movie review."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from cxplain.util.test_util import TestUtil\n",
    "\n",
    "num_words = 1024\n",
    "num_samples = 500\n",
    "(x_train, y_train), (x_test, y_test) = TestUtil.get_imdb(word_dictionary_size=num_words,\n",
    "                                                         num_subsamples=num_samples)\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we fit a review classification pipeline that first transforms the reviews into their term frequencyâ€“inverse document \n",
    "frequency (tf-idf) vector representation, and then fits a Random Forest classifier to these vector representations\n",
    "of the training data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from cxplain.util.count_vectoriser import CountVectoriser\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "explained_model = RandomForestClassifier(n_estimators=64, max_depth=5, random_state=1)\n",
    "\n",
    "counter = CountVectoriser(num_words)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "explained_model = Pipeline([('counts', counter),\n",
    "                            ('tfidf', tfidf_transformer),\n",
    "                            ('model', explained_model)])\n",
    "explained_model.fit(x_train, y_train);"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After fitting the review classification pipeline, we wish to explain its decisions, i.e. what input features were most relevant\n",
    "for a given pipeline prediction. To do so, we train a causal explanation (CXPlain) model that can learn to explain any\n",
    "machine-learning model using the same training data. In practice, we have to define:\n",
    "- `model_builder`: The type of model we want to use as our CXPlain model. In this case we are using a neural explanation model using\n",
    "a recurrent neural network (RNN) structure. \n",
    "- `masking_operation`: The masking operaion used to remove a certain input feature from the set of available input features. In this case we are using word drop masking, i.e. removing a word from the input sequence entirely.\n",
    "- `loss`: The loss function that we wish to use to measure the impact of removing a certain input feature from the set of available features. In most common use cases, this will be the mean squared error (MSE) for regression problems and the cross-entropy for classification problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "source": [
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "from cxplain import RNNModelBuilder, WordDropMasking, CXPlain\n",
    "\n",
    "model_builder = RNNModelBuilder(embedding_size=num_words, with_embedding=True,\n",
    "                                num_layers=2, num_units=32, activation=\"relu\", p_dropout=0.2, verbose=0,\n",
    "                                batch_size=32, learning_rate=0.001, num_epochs=2, early_stopping_patience=128)\n",
    "masking_operation = WordDropMasking()\n",
    "loss = binary_crossentropy"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Using this configuration, we now instantiate a CXPlain model and fit it to the same IMDB data that we used to fit the review classification pipeline model that we wish to explain.\n",
    "\n",
    "We also pad the movie reviews to the same length prior to fitting the CXPlain model since variable length inputs\n",
    "are currently not supported in CXPlain."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "explainer = CXPlain(explained_model, model_builder, masking_operation, loss)\n",
    "\n",
    "prior_test_lengths = map(len, x_test)\n",
    "x_train = pad_sequences(x_train, padding=\"post\", truncating=\"post\", dtype=int)\n",
    "x_test = pad_sequences(x_test, padding=\"post\", truncating=\"post\", dtype=int, maxlen=x_train.shape[1])\n",
    "explainer.fit(x_train, y_train);"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /Users/schwabp3/Documents/projects/venv/lib/python2.7/site-packages/tensorflow/python/keras/initializers.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/schwabp3/Documents/projects/venv/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/schwabp3/Documents/projects/cxplain/cxplain/backend/model_builders/base_model_builder.py:152: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n\n",
      "WARNING:tensorflow:From /Users/schwabp3/Documents/projects/venv/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can then use this fitted CXPlain model to explain the predictions of the explained model on the held-out test samples. Note that the importance scores are normalised to sum to a value of 1 and each score therefore represents the relative importance of each respective input word.\n",
    "\n",
    "\n",
    "(Although it would be possible, we do not request confidence intervals for the provided attributions in this example.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "source": [
    "attributions = explainer.explain(x_test)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now visualise the per-word attributions for a specific sample review from the test set using the `Plot` toolset available as part of CXPlain.\n",
    "\n",
    "Note that we first have to convert our input data from word indices back to actual word strings using `TestUtils.imdb_dictionary_indidces_to_words()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "<START> {0.000869052892085} <UNK> {0.00101536838338} watched {0.00123076280579} 8 {0.00117500138003} <UNK> {0.000994433648884} <UNK> {0.000954008253757} <UNK> {0.00104214868043} <UNK> {0.00127266219351} <UNK> {0.00109629391227} very {0.000929234724026} thought {0.000997570343316} <UNK> {0.00123121822253} and {0.00102737860288} very {0.0010709624039} well {0.000990054919384} done {0.00147655024193} movie {0.000871025433298} on {0.0014516452793} the {0.00144975376315} subject {0.00096174213104} of {0.00105090788566} the {0.00113586091902} death {0.00114432512783} <UNK> {0.0010641978588} <UNK> {0.000870429503266} more {0.00124163366854} <UNK> {0.000883863598574} and {0.00128600851167} <UNK> {0.00138137256727} than {0.000877433281858} it {0.00111598963849} <UNK> {0.00113100279123} \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cxplain.visualisation.plot import Plot\n",
    "\n",
    "plt.rcdefaults()\n",
    "\n",
    "np.random.seed(909)\n",
    "selected_index = np.random.randint(len(x_test))\n",
    "selected_sample = x_test[selected_index]\n",
    "importances = attributions[selected_index]\n",
    "prior_length = prior_test_lengths[selected_index]\n",
    "\n",
    "# Truncate to original review length prior to padding.\n",
    "selected_sample = selected_sample[:prior_length]\n",
    "importances = importances[:prior_length]\n",
    "words = TestUtil.imdb_dictionary_indidces_to_words(selected_sample)\n",
    "\n",
    "print(Plot.plot_attribution_nlp(words, importances))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}